// No version needed in include
//#version 430

#ifndef KERNELS_GLSL
#define KERNELS_GLSL


#extension GL_ARB_shading_language_include : enable
#include "/Materials/Common/Common"
#include "/Materials/Common/Random/Random"				
#include "/Materials/Common/Lighting/Lighting"
#line 13


#ifndef XTMY_OPERAND
	#define XTMY_OPERAND
	// X and Y are vecN, M is matN
	#define XtMY(X,M,Y) dot(X , (M * Y))
#endif

// constantes
#ifndef PI 
	#define PIx2e2 39.4784176044
	#define PIx2e3_2 15.7496099457
	#define PIx2 6.28318530718
	#define PI 3.14159265359
	#define PI_2 1.57079632679
	#define PI_3 1.0471975512
	#define PI_4 0.78539816339
	// TODO préacalculer sqrt(2PI), 2PI et (2PI)^(3/2)

	

#endif
// -------------------------- KERNELS RELATED STRUCTURE

// Surface position and normale extracted from textures
struct vertexPoint
{
	vec4 position;
	vec4 normale;
};

// Kernel's impulse generated by vertex shader (for a specific instanceID of an impulse)
// requires flat in and out in shaders
struct vertexGeneratedImpulse
{
	int profileID;
	int textureID;
	int validationInt;
	vec4 colorFromMap;
	mat4 toObjectSpace;
	mat4 fromObjectSpace;
	vertexPoint relatedSurfacePoint;
};

// Kernel configuration structure (refered as profile) (array of vec4 for modularity)
struct kernelProfile{
	vec4 data[10];
	// Index of data :
	// 0 -- ModelData :  isActive, model_texIDs_begin, model_texIDs_end
	// 1 -- kernelShape : rx, ry, scale, kernelPower
	// 2 -- distributionData : distribution_ID(pour distribution différentes par noyau), subdivision, densityPerCell, 
	// 3 -- ControlMapsIds : density_texID, distribution_texID, scale_texID, colorMap_texId
	// 4 -- ControlMapsInfluence : densityMap_influence, distributionMap_influence, scaleMap_influence, colorMap_influence
	// 5 -- lightData : attenuation, emittance, reflectance, volumetric obscurance factor
	// 6 -- ModelShape : rx, ry, rz
	// 7 -- distribution min
	// 8 -- distribution max
	// 9 -- color and transparency factor
};

// Kernel profiles buffer
layout (std430,binding=3) buffer KernelBuffer
{
	ivec4 nbModels;					// For vec4 alignment, data in x
	kernelProfile Kernels[];		// see kernelProfile structure above
};
// ----------------------------------------

// ------------------------------ SPLATTING
// return a 3D point in NDC space (projective division (w_clip) not kept)
vec3 projectPointToScreen(
	vec3 point,					// Point to project	
	mat4 pointToScreenSpace		// projection matrix from the point space to the screen space (projection * view * model * space)
	)
{
	vec4 point_MVP = pointToScreenSpace * vec4(point,1.0); // En réalité : pointToScreenSpace = pointToClipSpace (= ModelViewProjection par exemple)
	vec3 point_NDC = point_MVP.xyz / point_MVP.w;
	// calcul des coordonnées dans un pseudo espace écran ( passage de [-1;1] a [0;1])
	vec3 pointScreen;
	pointScreen = 0.5 + point_NDC * 0.5; 

	return pointScreen;
}

// return a 3D point in NDC space (projective division (w_clip) kept in w)
vec4 projectPointToNDCSpace(
	vec3 point,					// Point to project	
	mat4 pointToScreenSpace		// projection matrix from the point space to the screen space (projection * view * model * space)
	)
{

	vec4 point_MVP = pointToScreenSpace * vec4(point,1.0);
	vec4 point_NDC = vec4(point_MVP.xyz / point_MVP.w, 1.0 / point_MVP.w) ;
	// calcul des coordonnées dans un pseudo espace écran ( passage de [-1;1] a [0;1])
	vec4 pointScreen;
	pointScreen.xyz = (0.5 + point_NDC.xyz * 0.5);
	pointScreen.w = point_NDC.w; 
	return pointScreen;
}

// TODO : Function not tested
// Transform the fragment coordinate into the NDC coordinate for backward transformation from screen to opengl spaces (projection division kept in .w)
// ref : http://www.txutxi.com/?p=182
vec4 fragmentToNDC(
	vec4 fragmentCoord, // Fragment (gl_fragcoord like point with x & y in [0: viewport], z in [0,1] (non linearized) & w = 1.0 / projectionResult.w)
	vec2 viewPort 		// Screen Width and Height
	)
{
	vec4 point_NDC = vec4(
						fragmentCoord.x / viewPort.x, 
						fragmentCoord.y / viewPort.y, 
						fragmentCoord.z,
						fragmentCoord.w
						);

	point_NDC.xyz = point_NDC.xyz * 2.0 - 1.0;
	return point_NDC;
}

// TODO : Function not tested
// Transform the fragment coordinate into clip space ( clip space divide by projection.w = NDC)
vec4 fragmentToClipSpace(
	vec4 fragmentCoord, // Fragment (gl_fragcoord like point with x & y in [0: viewport], z in [0,1] & w = 1.0 / projectionResult.w)
	vec2 viewPort 		// Screen Width and Height
	)
{
	vec4 point_NDC = fragmentToNDC(fragmentCoord, viewPort);
	float projDivider = 1.0 / point_NDC.w;
	return vec4(point_NDC.xyz * projDivider , projDivider );
}


vec4 projectScreenPointToSpace(
	vec4 pointInFragmentSpace, 			// Fragment (gl_fragcoord like point with x & y in [0: viewport], z in [0,1] & w = 1.0 / projectionResult.w)
	vec2 viewportInformation, 			// Screen Width and Height
	mat4 screenToSpace 					// example for deprojection in object space : inverse(MVP)
	)
{
	return screenToSpace * fragmentToClipSpace(pointInFragmentSpace,viewportInformation);

}

// Juste a reminder for how to correctly compute homogeneous transformation
vec4 changingPointToFinalSpace(
	vec4 pointToChange, 
	mat4 pointSpaceToDestinationSpace
	)
{
	vec4 res = pointSpaceToDestinationSpace * pointToChange;
	res = res / res.w;
	return res;
}

//	@brief	Projection d'une coupe d'un espace 3D dans l'espace écran
//	@param	point Origine du plan de coupe
//	@param  
//	@return Matrice de transformation d'un point de la tranche dans l'espace écran (espace NDC renormalizé sur [0;1])
//	
mat3 project2DSpaceToScreen(vec3 point, vec3 slice_x, vec3 slice_y, mat4 planeToScreenSpace)
{
	
	vec2 PScreen = projectPointToScreen(point,planeToScreenSpace).xy;
	vec2 XScreen = projectPointToScreen(point + slice_x, planeToScreenSpace).xy;
	vec2 YScreen = projectPointToScreen(point + slice_y, planeToScreenSpace).xy;
	// Axis in screen space
	vec2 axeX = XScreen - PScreen;
	vec2 axeY = YScreen - PScreen;
	mat3 XYScreenSpace = mat3(	vec3(axeX,0),
								vec3(axeY,0),
								vec3(PScreen,1));
	return XYScreenSpace;
}
// ---------------------------------------------------------------------


// -------------------- Transformations
mat4 move(mat4 space, vec3 translation)
{
    mat4 translationMatrix = mat4(1.0);
    translationMatrix[3].xyz = translation;
    return translationMatrix * space;
}
mat4 rescale(mat4 space, vec3 scaling)
{
    mat4 scalingMatrix = mat4(1.0);
    scalingMatrix[0].x = scaling.x;
    scalingMatrix[1].y = scaling.y;
    scalingMatrix[2].z = scaling.z;
        
    return scalingMatrix * space;
}

mat4 rotate(mat4 space, vec3 aroundAxe, float angleInRadians)
{
    
    float cosA = cos(angleInRadians);
	float sinA = sin(angleInRadians);

	vec3 axis = normalize(aroundAxe);
	vec3 temp = (1.0 - cosA) * axis;
	mat4 rotationMatrix = mat4(1.0);
	rotationMatrix[0][0] = cosA + temp[0] * axis[0];
	rotationMatrix[0][1] = 0.0 	+ temp[0] * axis[1] + sinA * axis[2];
	rotationMatrix[0][2] = 0.0 	+ temp[0] * axis[2] - sinA * axis[1];

	rotationMatrix[1][0] = 0.0 	+ temp[1] * axis[0] - sinA * axis[2];
	rotationMatrix[1][1] = cosA + temp[1] * axis[1];
	rotationMatrix[1][2] = 0.0 	+ temp[1] * axis[2] + sinA * axis[0];

	rotationMatrix[2][0] = 0.0 	+ temp[2] * axis[0] + sinA * axis[1];
	rotationMatrix[2][1] = 0.0 	+ temp[2] * axis[1] - sinA * axis[0];
	rotationMatrix[2][2] = cosA + temp[2] * axis[2];

    return rotationMatrix * space;
}  


vec3 rotate(vec3 vector, vec3 aroundAxe, float angleInRadians) // from GLM matrix_transform.inl
{
	float cosA = cos(angleInRadians);
	float sinA = sin(angleInRadians);

	vec3 axis = normalize(aroundAxe);
	vec3 temp = (1.0 - cosA) * axis;
	mat3 rotationMatrix;
	rotationMatrix[0][0] = cosA + temp[0] * axis[0];
	rotationMatrix[0][1] = 0 	+ temp[0] * axis[1] + sinA * axis[2];
	rotationMatrix[0][2] = 0 	+ temp[0] * axis[2] - sinA * axis[1];

	rotationMatrix[1][0] = 0 	+ temp[1] * axis[0] - sinA * axis[2];
	rotationMatrix[1][1] = cosA + temp[1] * axis[1];
	rotationMatrix[1][2] = 0 	+ temp[1] * axis[2] + sinA * axis[0];

	rotationMatrix[2][0] = 0 	+ temp[2] * axis[0] + sinA * axis[1];
	rotationMatrix[2][1] = 0 	+ temp[2] * axis[1] - sinA * axis[0];
	rotationMatrix[2][2] = cosA + temp[2] * axis[2];

	vec3 result = rotationMatrix * vector;
	return normalize(result);

}
// -------------------- Matrix Transformations END


// OIT ------------------ Order independent transparency weighting function
//float weightFunction(float depth)
//{
//	//return max(1.0 , 1.0 + exp(-depth/10));
//	return clamp(100.0 / max(1.0 + exp(1.0+max(depth,0.01)),0.1),1.0,3000.0);
//}

//float weightFunction(float fragDepth)
//{
//	return clamp( 1.0 + fragDepth * 4000.0 ,1.0 , 4000.0);
//}

// For depth between 0.01 & 200
float weightFunction(float camDepth)
{
	return clamp( 1.0 + ( (abs(camDepth) - 0.01) / (199.99) ) * 10000.0 ,1.0, 10000.0);
}

float customOITfunction(float depth, float depthMin, float depthMax)
{
	float depthInRange = (abs(depth) - depthMin) / (depthMax - depthMin);
	float maxWeight = 10000.0;
	return clamp(maxWeight * 1.0 / pow(2*depthInRange + 1.0, 6.0), 1.0 , maxWeight + 1.0);
}

float shellWeightFunction(float height)
{
	return clamp(pow( height * 10,4.0 ), 1.0, 100.0);
}


float macGuireEq7(float depth)
{
	return clamp( 10.0 / (0.00005 + pow(abs(depth) / 5.0, 3) + pow(abs(depth) / 200.0, 6) ) , 0.01, 3000.0); 
}

float macGuireEq8(float depth)
{
	return clamp( 10.0 / (0.00005 + pow(abs(depth) / 10.0, 3) + pow(abs(depth) / 200.0, 6) ) , 0.01, 3000.0); 
}

float specialWeightFunction(float Z)
{
	return clamp(1.0 / (0.00005 + pow(abs(Z),6.0)), 1.0, 10000000.0);
}

float macGuireEq9(float depth)
{
	return clamp( 0.03 / (0.00005 + pow(abs(depth) / 200.0, 4) ) , 0.01, 3000.0); 
}

float macGuireEq10(float depth)
{
	return clamp( 10.0 / (0.00005 + pow(abs(depth) / 10.0, 3) + pow(abs(depth) / 200.0, 6) ) , 0.01, 3000.0); 
}
// OIT ------------------ Order independent transparency weighting function END

// -------------------------------------------------------------------------------
//					KERNELS COMPUTATION FUNCTIONS
// -------------------------------------------------------------------------------

vec3 getQuadraticNormal(vec4 X, mat4 Q) 
{
	return normalize( vec3(	dot(2.0 * Q[0],X), dot(2.0 * Q[1],X), dot(2.0 * Q[2],X) ) );
}



/////// Vertex shader functions

void setRandomSeedForKernelNum(int kernelNum)
{
	for(int i = 0; i < kernelNum ; i++)
	{
		// shift de la seed pour obtenir le bon état du prng
		randomVec2();	/*randomPosition */
		random();		/* random height */
		random();		/*theta  */
		random();		/*phi  */
		random();		/*density  */
		random();		/*scale  */
		random();		/*kernelTextureID  */
		random();		/*chanceOfPoping  */
	}
}


mat4 createKernelSpace(
	in kernelProfile element, 
	in vec3 position, 
	in vec3 xDirBase,
	in vec3 yDirBase, 
	in vec3 wantedDirInTangentSpace, 
	in float scale
	)
{
	
	
	// Espace de transformation de l'espace du noyau dans l'espace objet (espace locale élémentaire)
	mat4 kernelSpace = mat4(1.0);
	kernelSpace[0].xyz = normalize(xDirBase);
	kernelSpace[1].xyz = normalize(yDirBase);
	kernelSpace[2].xyz = normalize(cross(kernelSpace[0].xyz,kernelSpace[1].xyz));
	kernelSpace[3].xyz = position;
	kernelSpace[3].w = 1.0;
	
	// Pour le moment je suppose que le xDirBase et yDirBase passer en parametres sont la tangente et la normale
	mat3 TBN = mat3(xDirBase,kernelSpace[2].xyz,yDirBase);

	vec3 newDirection = wantedDirInTangentSpace.xyz;
	vec3 normalFromTSpace = normalize(TBN * newDirection); // repassage en objet
	vec3 dirFromTSpace = normalize(xDirBase);
	dirFromTSpace = length(newDirection.xy) > 0.0 ? normalize(TBN * vec3(newDirection.xy,0) ) : dirFromTSpace;

	// calcul des angles de rotations dans la carte
	float cosTheta = dot(normalize(xDirBase),dirFromTSpace);
	float cosPhi = dot(normalize(yDirBase),normalFromTSpace);
	float theta = sign(cosTheta) * acos(cosTheta);
	float phi = sign(cosPhi) * acos(cosPhi);
	
	kernelSpace[0].xyz = rotate(kernelSpace[0].xyz, kernelSpace[1].xyz, theta);
	kernelSpace[1].xyz = rotate(kernelSpace[1].xyz, kernelSpace[0].xyz, -phi);
	kernelSpace[2].xyz = normalize(cross(kernelSpace[0].xyz,kernelSpace[1].xyz));

	kernelSpace[2].xyz = rotate(kernelSpace[2].xyz, kernelSpace[1].xyz, randomIn(-PI_4,PI_4));
	// */

	// rescaling
	vec3 kernelScale = element.data[6].xyz * (element.data[6].w * scale);
	kernelSpace[0].xyz *= kernelScale.x;
	kernelSpace[1].xyz *= kernelScale.y;
	kernelSpace[2].xyz *= kernelScale.z;
	
	return kernelSpace;
}


// Function to return (as a struct) the minimal information required to compute the kernel contribution
vertexGeneratedImpulse getNewKernelSpace(
	in int profileID,							// ID in the Kernels[] array from the SSBO
	in vec4 cellInfo, 							// cellInfo.xy = distributionCell.xy, cellInfo.zw = nbCellsPerAxis
	in int numKernelInCell,						// number of the kernel in the distribution cell
	in float gridHeight,
	in sampler2DArray surfaceData,				// 3D position, normal, tangent
	in sampler2DArray kernelsDensityMaps,		// kernel parameters : density mapped over the surface
	in sampler2DArray kernelsScaleMaps,			// kernel parameters : scale factor mapped over the surface
	in sampler2DArray kernelsDistributionMaps,	// kernel parameters : normal distribution mapped over the surface (kernels direction
	in sampler2DArray kernelsColorMaps	// kernel parameters : normal distribution mapped over the surface (kernels direction
	)
{
	vertexGeneratedImpulse surfaceKernel;

	kernelProfile toUse = Kernels[profileID];

	surfaceKernel.profileID = profileID;
	// PRNG init
	initRandom(ivec2(cellInfo.xy));

	// random variable declaration
	vec2 randomPosition = vec2(0.0);
	float density;
	float scale;
	float chanceOfPoping;
	float theta;
	float phi;

	// Shifting the seed to he correct position
	setRandomSeedForKernelNum(numKernelInCell);
	
	// Création de l'espace d'évaluation dans l'espace objet
	// Position aléatoire : random dans la cellule
	randomPosition = randomInFrame( cellInfo.xy + 0.5, vec2(toUse.data[7].xy), vec2(toUse.data[8].xy) );
	randomPosition = clamp(randomPosition / cellInfo.zw ,vec2(0.001), vec2(0.999));
	
	// généré H entre h*(min/2) et max
	float h = -gridHeight + randomIn(toUse.data[7].z, toUse.data[8].z) * 2.0 * gridHeight;

	// ----------------- Accès textures
	// Surface attributes at this position
	surfaceKernel.relatedSurfacePoint.position = textureLod(surfaceData,vec3(randomPosition,0), 0);
	surfaceKernel.relatedSurfacePoint.normale = textureLod(surfaceData,vec3(randomPosition,1), 0);
	surfaceKernel.relatedSurfacePoint.normale.xyz = normalize(surfaceKernel.relatedSurfacePoint.normale.xyz);

	// Carte de controle
	vec4 densityMap = textureLod(kernelsDensityMaps,vec3(randomPosition,int(toUse.data[3].x)),0);
	vec4 distributionMap = textureLod(kernelsDistributionMaps,vec3(randomPosition,int(toUse.data[3].y)), 0) * 2.0 - 1.0;
	vec4 scaleMap = textureLod(kernelsScaleMaps, vec3(randomPosition,int(toUse.data[3].z)),0);
	surfaceKernel.colorFromMap = textureLod(kernelsColorMaps, vec3(randomPosition,int(toUse.data[3].w)),0);
	// -------------------------------------

	// Direction random selon theta et phi
	theta = randomIn(-PI, PI);
	phi = randomIn(PI_4, PI);
	vec3 randomDir = normalize(vec3(sin(theta) * cos(phi),sin(theta) * sin(phi),cos(theta)));
	// Repasser random dir en espace tangent
	randomDir = (randomDir + 1.0) * 0.5;
	vec3 wantedDir = distributionMap.xyz * toUse.data[4].y + (1.0 - toUse.data[4].y) * randomDir;

	density =  toUse.data[4].x * densityMap.x + (1.0 -  toUse.data[4].x) * randomIn(0.0,1.0);
	scale =  toUse.data[4].z * scaleMap.x + (1.0 -  toUse.data[4].z) * randomIn(0.0,1.0);
	
	surfaceKernel.textureID = int(randomIn( toUse.data[0].y, toUse.data[0].z + 0.9));
	chanceOfPoping = random();

	surfaceKernel.toObjectSpace = createKernelSpace(	toUse, 
														surfaceKernel.relatedSurfacePoint.position.xyz + h * surfaceKernel.relatedSurfacePoint.normale.xyz, 
														normalize( textureLod(surfaceData,vec3(randomPosition,2), 0).xyz ),
														surfaceKernel.relatedSurfacePoint.normale.xyz, 
														wantedDir, 
														scale * gridHeight
														);
	surfaceKernel.fromObjectSpace = inverse(surfaceKernel.toObjectSpace);
	surfaceKernel.validationInt = (surfaceKernel.relatedSurfacePoint.position.w == 1.0 && density > 0.0 && chanceOfPoping <= density && scale > 0.0) ? 0 : 1;

	return surfaceKernel;

}

/////// Fragment shader functions

mat4 quadratic(float radius)
{
	return mat4(
			vec4(1,0,0,0),
			vec4(0,1,0,0),
			vec4(0,0,1,0),
			vec4(0,0,0,-radius)
		);
}

float getKernelContribution(
	kernelProfile element,
	vec3 posInKernelSpace, 
	vec3 dxKernelSpace, 
	vec3 dyKernelSpace,
	vec3 dzKernelSpace)
{
	mat3 J = mat3(dxKernelSpace,dyKernelSpace,dzKernelSpace);
	// Gaussienne dans l'espace du noyau (a paramétrer avec rx et ry)
	mat3 Vrk = mat3(
		vec3(element.data[1].x / element.data[1].w,0,0),
		vec3(0,element.data[1].y / element.data[1].w,0),
		vec3(0,0,element.data[1].z / element.data[1].w)
		);

	// filtrage : application de la jacobienne
	Vrk += (J * transpose(J));
	mat3 _Vrk = inverse(Vrk);
	//float d_Vrk = sqrt(determinant(_Vrk));
	float dVrk = sqrt(determinant(Vrk));
	float distanceEval = XtMY(posInKernelSpace,_Vrk,posInKernelSpace);
	float g_vrk =  (1.0 / (PIx2e3_2 * dVrk)) * exp(-0.5 * distanceEval);
	g_vrk = clamp( element.data[1].w * g_vrk,0.0, 1.0);

	return g_vrk;
}


// Kernel sample base information
struct impulseSample
{
	vec4 color;
	float depth;
	float heightFromGround;
	bool isValid;
};

// Fragment code
impulseSample getImpulseSample(
	// Kernel config
	in kernelProfile element,
	// Kernel position info
	in vec3 kernelPos,
	in vec3 kernelPosRight,
	in vec3 kernelPosUp,
	// Kernel texture info
	in sampler2DArray kernelModelArray,
	in int kernelTextureID,
	// Transformation matrices
	in mat4 kernelToObjectSpace,
	in mat4 objectToWorldSpace,
	// Depth buffer
	in float depthBufferValue,
	// Surface info
	in vec3 surfacePosition,
	in vec3 surfaceNormal,
	// Shell height
	in float shellHeight
	)
{
	impulseSample generatedImpulse;

	vec3 kernelFragmentPosition = kernelPos;
	vec3 kernelFragmentRight = kernelPosRight;
	vec3 kernelFragmentUp = kernelPosUp;
	
	// Jacobienne du noyau dans l'espace écran
	vec3 dx = vec3(kernelFragmentRight.xy - kernelFragmentPosition.xy,0.0);
	vec3 dy = vec3(kernelFragmentUp.xy - kernelFragmentPosition.xy,0.0);
	vec3 dz = vec3(0.0,0.0,0.0);

	float g_vrk = getKernelContribution(
		element, 
		kernelFragmentPosition,
		dx, dy, dz);


	vec2 kernelTextureCoordinates = ((kernelFragmentPosition.xy) + vec2(0.5,0)).yx;
	vec2 kernelTextureDx = vec2(0.0);
	vec2 kernelTextureDy = vec2(0.0);
	kernelTextureDx = ((kernelFragmentRight.xy) + vec2(0.5,0)).yx;
	kernelTextureDy = ((kernelFragmentUp.xy) + vec2(0.5,0)).yx;
	kernelTextureDx = kernelTextureDx - kernelTextureCoordinates;
	kernelTextureDy = kernelTextureDy - kernelTextureCoordinates;
	

	vec3 objectPosition = 	(kernelToObjectSpace * vec4(kernelFragmentPosition.xy,0.0,1.0)).xyz;	
	vec3 objectNormal = 	normalize(cross(kernelToObjectSpace[0].xyz,kernelToObjectSpace[1].xyz));
	vec3 worldPosition= 	(objectToWorldSpace * vec4(objectPosition,1.0)).xyz;

	//vec3 worldNormal= 		normalize((objectToWorldSpace * vec4(objectNormal,0.0)).xyz);
	//vec3 worldGroundNormal=	normalize((objectToWorldSpace * vec4(surfaceNormal.xyz,0.0)).xyz);

	// Version moche mais qui doit fonctionner
	vec3 worldNormal = (objectToWorldSpace * vec4(objectPosition + objectNormal,1.0)).xyz;
	worldNormal = normalize(worldNormal - worldPosition);
	vec3 camDirInWorld = normalize( worldPosition - inverse(View)[3].xyz );
	if(dot(camDirInWorld,worldNormal) > 0.0 ) worldNormal = -worldNormal;

	// presque pareil pour la ground normale
	vec3 worldGroundPosition = (objectToWorldSpace * vec4(surfacePosition,1.0)).xyz;
	vec3 worldGroundNormal = (objectToWorldSpace * vec4(surfacePosition + surfaceNormal.xyz,1.0) ).xyz;
	worldGroundNormal = normalize(worldGroundNormal - worldGroundPosition);

	bool isAValidSample = kernelFragmentPosition.y > 0  
								&&  g_vrk > 0.05 ;

	bool isInTextureSpace =	all( 
								bvec2( 
									all(greaterThan(kernelTextureCoordinates,vec2(0.01))) , 
									all(lessThan(kernelTextureCoordinates,vec2(0.99)))
									) 
								)
							;

	vec4 kernelColor = textureGrad(
							kernelModelArray,
							vec3(kernelTextureCoordinates, kernelTextureID ), 
							kernelTextureDx, 
							kernelTextureDy );
	
	// gaussienne uniquement sur l'alpha pour ne pas modifier la couleur de la texture
	// Requiert une gaussienne adapté
	kernelColor.a *= g_vrk; 
	
	vec3 VV = (objectPosition.xyz - surfacePosition.xyz);
	generatedImpulse.heightFromGround = dot(normalize(surfaceNormal.xyz),VV);

	float VolumetricOcclusionFactor = generatedImpulse.heightFromGround / (shellHeight * (element.data[6].w));
	
	
	generatedImpulse.color = addBoulanger3(	
									worldPosition,
       								kernelColor,
       								worldNormal,
       								worldGroundNormal,
       								VolumetricOcclusionFactor,
									element.data[5].z,
									element.data[5].x,
									element.data[5].y,
									element.data[5].w
       							);

	
	// sample dans l'espace camera pour calcul de la profondeur
	vec4 pointInCamera = View * objectToWorldSpace * vec4(objectPosition , 1.0);

	// fragment position
	vec4 pointInScreen = Proj * pointInCamera;
	pointInScreen.xyz /= pointInScreen.w;
	pointInScreen.xyz = vec3(0.5) + pointInScreen.xyz * vec3(0.5);

	generatedImpulse.depth = -pointInCamera.z;

	// Validation
	generatedImpulse.isValid = 	kernelColor.a > 0.01 
								&& abs(pointInScreen.z) <= depthBufferValue 
								&& isAValidSample 
								&& isInTextureSpace;

	//generatedImpulse.color.rgb = worldNormal;

	return generatedImpulse;
}


bool getKernelIntersectionData(
		mat4 evaluationToQuadraticSpace, 		// inverse(S * K * T), S = object to point space, K = kernel to object space, T = quadratic parameters to kernel space 
		vec4 evaluatedCoord,					
		out vec3 positionInEvaluationSpace,		// Position in evaluated point space
		out vec3 normalInEvaluationSpace		// Normale in evaluated point space
	)
{
	
	vec4 Xp_prime = evaluationToQuadraticSpace * vec4(evaluatedCoord.xy,0,evaluatedCoord.w);
	
	// Quadratic sphérique de rayon 1 (quadratic de base)
	mat4 D = quadratic(1.0);

	// solving the quadratic polynom of the ray projected in the quadratic space
	float A = XtMY(evaluationToQuadraticSpace[2],D,evaluationToQuadraticSpace[2]);
	float B = 2.0 * XtMY(Xp_prime,D,evaluationToQuadraticSpace[2]);
	float C = XtMY(Xp_prime,D,Xp_prime);

	float delta = (B * B) - (4 * A * C);
	float delta_root = sqrt(delta);
	float A_2 = 2.0 * A;
	
	if (delta < 0) return false;
	else
	{
		float newZ  = 0.0;
		float signe = 0.0;
		if(delta == 0)
		{
			float root = (-B / A_2); 
			signe = sign(root);
			newZ = abs(root);
		}
		else
		{
			// Supposition : l'évaluation se ferait par rapport à l'espace camera (ou post projection)
			// On ne garde donc que la solution la plus petite en valeur absolue
			float root1 = (-B - delta_root) / A_2;
			float signe_r1 = sign(root1);
			root1 = abs(root1);

			float root2 = (-B + delta_root) / A_2;
			float signe_r2 = sign(root2);
			root2 = abs(root2);

			newZ = min(root1,root2);
			signe = root1 < root2 ? signe_r1 : signe_r2;
		}

		positionInEvaluationSpace = vec3(evaluatedCoord.xy, signe * newZ);
		normalInEvaluationSpace = normalize( ( inverse(evaluationToQuadraticSpace) * vec4( (evaluationToQuadraticSpace * vec4(positionInEvaluationSpace,1.0)).xyz,0.0 ) ).xyz );
		return true;
	}
}


// TODO enlever les OUT de la fonction et utiliser un retour par structure à la place*


// XYZ : normal direction in evaluation space, W : evaluation result
//vec4 impulseNormalAndValue(
//	mat4 parameterSpace,
//	vec3 evaluatedPosition
//	)
//{
//	mat4 varianceMatrix = inverse(T);
//	vec3 normal = getQuadraticNormal(evaluatedPosition,varianceMatrix)
//
//	float dist = XtMY()
//
//}



// Kernels evaluation functions
bool intersection_quadraticKernel(
	vec3 kernelShift, 				// to translate the kernel in its evaluation
    vec3 kernelScale,				// to rescale the kernel in its evaluation
    vec4 cameraSpaceCoord,			// evaluation coordinates in camera Space
    mat4 KernelToCameraSpace,		// Transformation Matrix form kernel evaluation space to camera space
    out vec3 intersectedPosition,	// OUT : return the position of the first intersection in camera space
    out vec3 intersectedNormal		// OUT : return the normal of the first intersection in camera space (To renormalize)
	)
{
	mat4 shift, rotation, scale;
	 
	 // Paramètre de l'espace de la gaussienne : Noyau 1 (gaussienne normale shifter de 0.5 en xyz)
    shift = move(mat4(1.0), kernelShift);
    rotation = rotate(mat4(1.0),vec3(0.0,0.0,1.0),0.0);	
    scale = rescale(mat4(1.0),vec3(0.5) * kernelScale); // Scale de base à 0.5 pour avoir un diamtère de 1

    mat4 T =  (shift * rotation * scale);

    mat4 CameraToQuadraticSpace = inverse(KernelToCameraSpace * T);

    bool isIntersected = getKernelIntersectionData(
		CameraToQuadraticSpace, 
		cameraSpaceCoord,
		intersectedPosition,
		intersectedNormal
	);

	return isIntersected;
}


// --------------------------- Noyaux gaussien volumique
float computeKernelBase(
	vec3 kernelPos, 
    vec4 kernelScale,
    vec3 evalPos,
    out vec3 normal
    )
{
    mat4 _Vrk = mat4(1.0);
	float distanceEval = 0.0;
	float dVrk = 0.0;
	float g_vrk = 0.0;
   
   	// modification : la puissance sera maintenant le W de la 
    
    mat4 shift, rotation, scale;
    
    mat4 D = mat4(1.0); 
    
    // A quadratic surface can be defined as Q = transpose(inverse(T)) * D * inverse(T) with a D its base diagonal matrix (with D_ii = 1 and D_33 = -1)
    // T is called "parameter space" to express the quadratic as a "transformed" basic quadratic
    mat4 T = mat4(1.0);
    shift = move(mat4(1.0),vec3(0.0) + kernelPos);
    rotation = rotate(mat4(1.0),vec3(0.0,0.0,1.0),0.0);	// Todo 
    scale = rescale(mat4(1.0),vec3(1.0) * kernelScale.xyz );
    T = shift * rotation * scale;
    mat4 _T = inverse(T);

    // normal vector = gradient = (dp/dx, dp/dy, dp/dz)

    vec4 point = vec4(evalPos,1.0);
    vec4 quadraticPoint = _T * point;
    normal = normalize((T * vec4(quadraticPoint.xyz,0.0)).xyz);

	_Vrk = transpose(_T) * D * _T;
    distanceEval = (XtMY(point,_Vrk,point));
	dVrk = sqrt(abs(determinant(_Vrk)));
	g_vrk +=  clamp( (dVrk / (PIx2e3_2)) * exp(-0.5 * distanceEval), 0.0, 1.0); 
    	
    float power = kernelScale.w;
    return ( (g_vrk = clamp(power * g_vrk,0.0, 1.0)) < 0.01 ? 0.0 : g_vrk) ;
    
}


// test du compute à partir de la fonction modifier
vec4 baseKernelNormalAndValue(
	vec3 kernelPos, 
    vec3 kernelScale,
    vec3 evalPos
    )
{
	vec4 normalAndValue = vec4(0.0);

    mat4 _Vrk = mat4(1.0);
	float distanceEval = 0.0;
	float dVrk = 0.0;
	float g_vrk = 0.0;
   
   	// modification : la puissance sera maintenant le W de la 
    
    mat4 shift, rotation, scale;
    
    mat4 D = mat4(1.0); 
    
    // A quadratic surface can be defined as Q = transpose(inverse(T)) * D * inverse(T) with a D its base diagonal matrix (with D_ii = 1 and D_33 = -1)
    // T is called "parameter space" to express the quadratic as a "transformed" basic quadratic
    mat4 T = mat4(1.0);
    shift = move(mat4(1.0),vec3(0.0) + kernelPos);
    rotation = rotate(mat4(1.0),vec3(0.0,0.0,1.0),0.0);	// Todo 
    scale = rescale(mat4(1.0),vec3(0.15) * kernelScale);
    T = shift * rotation * scale;
    mat4 _T = inverse(T);

    vec4 point = vec4(evalPos,1.0);

	_Vrk = transpose(_T) * D * _T;

	normalAndValue.xyz = getQuadraticNormal(point,_Vrk);
	distanceEval = (XtMY(point,_Vrk,point));
	dVrk = sqrt(determinant(_Vrk));
	g_vrk +=  clamp( (dVrk / (PIx2e3_2)) * exp(-0.5 * distanceEval), 0.0, 1.0); 
    	
    float power = 1.0;
	normalAndValue.w = ( (clamp(power * g_vrk,0.0, 1.0)) < 0.01 ? 0.0 : g_vrk);

    return normalAndValue ;
    
}



// test du compute à partir de la fonction modifier
float computeNewKernelBase(
	vec3 kernelPos, 
    vec3 kernelScale,
    vec3 evalPos
    )
{
    mat4 _Vrk = mat4(1.0);
	float distanceEval = 0.0;
	float dVrk = 0.0;
	float g_vrk = 0.0;
   
   	// modification : la puissance sera maintenant le W de la 
    
    mat4 shift, rotation, scale;
    
    mat4 D = mat4(1.0); 
    
    // A quadratic surface can be defined as Q = transpose(inverse(T)) * D * inverse(T) with a D its base diagonal matrix (with D_ii = 1 and D_33 = -1)
    // T is called "parameter space" to express the quadratic as a "transformed" basic quadratic
    mat4 T = mat4(1.0);
    shift = move(mat4(1.0),vec3(0.0) + kernelPos);
    rotation = rotate(mat4(1.0),vec3(0.0,0.0,1.0),0.0);	// Todo 
    scale = rescale(mat4(1.0),vec3(0.15) * kernelScale);
    T = shift * rotation * scale;
    mat4 _T = inverse(T);

    vec4 point = vec4(evalPos,1.0);

	_Vrk = transpose(_T) * D * _T;
    distanceEval = (XtMY(point,_Vrk,point));
	dVrk = sqrt(determinant(_Vrk));
	g_vrk +=  clamp( (dVrk / (PIx2e3_2)) * exp(-0.5 * distanceEval), 0.0, 1.0); 
    	
    float power = 1.0;
    return ( (clamp(power * g_vrk,0.0, 1.0)) < 0.01 ? 0.0 : g_vrk) ;
    
}


vec4 ellipsoid(
	vec3 kernelPos, 
    vec3 kernelScale,
    vec3 evalPos
	)
{
	vec4 elips = 	baseKernelNormalAndValue( vec3(0.0) + kernelPos,vec3(1.0,1.0,1.0) * kernelScale, evalPos );

	vec4 result;
	result.xyz = normalize( elips.xyz * elips.w);
	result.w = clamp(elips.w,0.0,1.0);

	return result;
}

vec4 donut(
    	vec3 kernelPos, 
    	vec3 kernelScale,
    	vec3 evalPos
    )
{
	vec4 ring = 	baseKernelNormalAndValue( vec3(0.0) + kernelPos,vec3(1.0,0.5,1.0) * kernelScale, evalPos );
	vec4 center =  - baseKernelNormalAndValue( vec3(0.0,0.0,0.0) + kernelPos,vec3(0.5,10.0,0.5) * kernelScale, evalPos );

	vec4 result;
	result.xyz = normalize( ring.xyz * ring.w + center.xyz * center.w);
	result.w = clamp(ring.w + center.w,0.0,1.0);

	return result;
}
   
vec4 champignon(
	vec3 kernelPos, 
    vec3 kernelScale,
    vec3 evalPos
    )
{

	vec4 chapeau = baseKernelNormalAndValue( vec3(0.0,0.3,0.0) + kernelPos,vec3(1.0,0.15,1.0) * kernelScale, evalPos );
	vec4 tronc = baseKernelNormalAndValue( vec3(0.0,0.0,0.0) + kernelPos,vec3(0.15,0.6,0.15) * kernelScale, evalPos );
	vec4 pied = baseKernelNormalAndValue( vec3(0.0,-0.3,0.0) + kernelPos,vec3(0.3,0.3,0.3) * kernelScale, evalPos );

	vec4 result;
	result.xyz = normalize( chapeau.xyz * chapeau.w + tronc.xyz * tronc.w + pied.xyz * pied.w );
	result.w = clamp(chapeau.w + tronc.w + pied.w,0.0,1.0);

	return result;
}

vec4 selectedVolumetricKernel(
	vec3 kernelPos, 
    vec3 kernelScale,
    vec3 evalPos,
    int ID
    )
{
	vec4 result;
	switch (ID)
	{
		case 0:
			result = ellipsoid(kernelPos,kernelScale,evalPos);	
			break;
		case 1:
			result =  donut(kernelPos,kernelScale,evalPos);
			break;
		case 2:
			result =  champignon(kernelPos,kernelScale,evalPos);
			break;
		default:
			//result = ellipsoid(kernelPos,kernelScale,evalPos);
			break;

	}

	return result;
}

float JMD_1(
    	vec3 kernelPos, 
    	vec3 kernelScale,
    	vec3 evalPos
    )
{
    return clamp(
        	computeNewKernelBase( vec3(0.0,-0.3,0.0) + kernelPos,vec3(0.15,0.15,0.15) * kernelScale, evalPos )
        	+ computeNewKernelBase( vec3(0.0,0.0,0.0) + kernelPos,vec3(0.05,0.5,0.05) * kernelScale, evalPos )
        ,0.0,1.0);
}

float JMD_2(
    	vec3 kernelPos, 
    	vec3 kernelScale,
    	vec3 evalPos
    )
{
    return clamp(
        	computeNewKernelBase( vec3(0.0,0.0,0.0) + kernelPos,vec3(0.15,0.6,0.15) * kernelScale, evalPos )
        	+ computeNewKernelBase( vec3(0.0,0.3,0.0) + kernelPos,vec3(1.0,0.15,1.0) * kernelScale, evalPos )
        	+ computeNewKernelBase( vec3(0.0,-0.3,0.0) + kernelPos,vec3(0.3,0.3,0.3) * kernelScale, evalPos )
        ,0.0,1.0);
}


float computeStars( 
	vec3 kernelPos, 
    vec3 kernelScale,
    vec3 evalPos
    )
{
     mat4 _Vrk = mat4(1.0);
	float distanceEval = 0.0;
	float dVrk = 0.0;
	float g_vrk = 0.0;
   
    
    mat4 shift, rotation, scale, gaussianSpaceMatrix;
    
    // Paramètres de base du noyaux (Idéalement, il me faudrait trouver une matrice qui me réparti la densité
	float power = 5.0;
    mat4 gaussianBase = mat4(1.0); // Gaussienne sphérique
    gaussianBase[0].x = sqrt(PI * power);
    gaussianBase[1].y = sqrt(PI * power);
    gaussianBase[2].z = sqrt(PI * power);
    
    // Paramètre de l'espace de la gaussienne : Noyau 1 (gaussienne normale shifter de 0.5 en xyz)
    shift = move(mat4(1.0),vec3(0.0) + kernelPos);
    rotation = rotate(mat4(1.0),vec3(0.0,0.0,1.0),0.0);	// Todo 
    scale = rescale(mat4(1.0),vec3(0.1,0.5,0.1) * kernelScale);
    gaussianSpaceMatrix = shift * rotation * scale;  
    gaussianSpaceMatrix = inverse(gaussianSpaceMatrix);
	_Vrk = transpose(gaussianSpaceMatrix) * gaussianBase * gaussianSpaceMatrix;
    distanceEval = (XtMY(vec4(evalPos,1.0),_Vrk,vec4(evalPos,1.0)));
	dVrk = sqrt(determinant(gaussianSpaceMatrix));
	g_vrk +=  clamp( (dVrk / (2.0 * PI)) * exp(-0.5 * distanceEval), 0.0, 1.0); 
    
    // Paramètre de l'espace de la gaussienne : Noyau 1 (gaussienne normale shifter de 0.5 en xyz)
    shift = move(mat4(1.0),vec3(0.0) + kernelPos);
    rotation = rotate(mat4(1.0),vec3(0.0,0.0,1.0),0.0);	// Todo 
    scale = rescale(mat4(1.0),vec3(0.5,0.1,0.1) * kernelScale);
    gaussianSpaceMatrix = shift * rotation * scale;  
    gaussianSpaceMatrix = inverse(gaussianSpaceMatrix);
	_Vrk = transpose(gaussianSpaceMatrix) * gaussianBase * gaussianSpaceMatrix;
    distanceEval = (XtMY(vec4(evalPos,1.0),_Vrk,vec4(evalPos,1.0)));
	dVrk = sqrt(determinant(gaussianSpaceMatrix));
	g_vrk +=  clamp( (dVrk / (2.0 * PI)) * exp(-0.5 * distanceEval), 0.0, 1.0);

	// Paramètre de l'espace de la gaussienne : Noyau 1 (gaussienne normale shifter de 0.5 en xyz)
    shift = move(mat4(1.0),vec3(0.0) + kernelPos);
    rotation = rotate(mat4(1.0),vec3(0.0,0.0,1.0),PI_4);	// Todo 
    scale = rescale(mat4(1.0),vec3(0.1,0.5,0.1) * kernelScale);
    gaussianSpaceMatrix = shift * rotation * scale;  
    gaussianSpaceMatrix = inverse(gaussianSpaceMatrix);
	_Vrk = transpose(gaussianSpaceMatrix) * gaussianBase * gaussianSpaceMatrix;
    distanceEval = (XtMY(vec4(evalPos,1.0),_Vrk,vec4(evalPos,1.0)));
	dVrk = sqrt(determinant(gaussianSpaceMatrix));
	g_vrk +=  clamp( (dVrk / (2.0 * PI)) * exp(-0.5 * distanceEval), 0.0, 1.0); 
    
    // Paramètre de l'espace de la gaussienne : Noyau 1 (gaussienne normale shifter de 0.5 en xyz)
    shift = move(mat4(1.0),vec3(0.0) + kernelPos);
    rotation = rotate(mat4(1.0),vec3(0.0,0.0,1.0),PI_4);	// Todo 
    scale = rescale(mat4(1.0),vec3(0.5,0.1,0.1) * kernelScale);
    gaussianSpaceMatrix = shift * rotation * scale;  
    gaussianSpaceMatrix = inverse(gaussianSpaceMatrix);
	_Vrk = transpose(gaussianSpaceMatrix) * gaussianBase * gaussianSpaceMatrix;
    distanceEval = (XtMY(vec4(evalPos,1.0),_Vrk,vec4(evalPos,1.0)));
	dVrk = sqrt(determinant(gaussianSpaceMatrix));
	g_vrk +=  clamp( (dVrk / (2.0 * PI)) * exp(-0.5 * distanceEval), 0.0, 1.0);


	// Paramètre de l'espace de la gaussienne : Noyau 1 (gaussienne normale shifter de 0.5 en xyz)
    shift = move(mat4(1.0),vec3(0.0) + kernelPos);
    rotation = rotate(mat4(1.0),vec3(0.0,1.0,0.0),PI_4);	// Todo 
    scale = rescale(mat4(1.0),vec3(0.1,0.5,0.1) * kernelScale);
    gaussianSpaceMatrix = shift * rotation * scale;  
    gaussianSpaceMatrix = inverse(gaussianSpaceMatrix);
	_Vrk = transpose(gaussianSpaceMatrix) * gaussianBase * gaussianSpaceMatrix;
    distanceEval = (XtMY(vec4(evalPos,1.0),_Vrk,vec4(evalPos,1.0)));
	dVrk = sqrt(determinant(gaussianSpaceMatrix));
	g_vrk +=  clamp( (dVrk / (2.0 * PI)) * exp(-0.5 * distanceEval), 0.0, 1.0); 
    
    // Paramètre de l'espace de la gaussienne : Noyau 1 (gaussienne normale shifter de 0.5 en xyz)
    shift = move(mat4(1.0),vec3(0.0) + kernelPos);
    rotation = rotate(mat4(1.0),vec3(0.0,1.0,0.0),PI_4);	// Todo 
    scale = rescale(mat4(1.0),vec3(0.5,0.1,0.1) * kernelScale);
    gaussianSpaceMatrix = shift * rotation * scale;  
    gaussianSpaceMatrix = inverse(gaussianSpaceMatrix);
	_Vrk = transpose(gaussianSpaceMatrix) * gaussianBase * gaussianSpaceMatrix;
    distanceEval = (XtMY(vec4(evalPos,1.0),_Vrk,vec4(evalPos,1.0)));
	dVrk = sqrt(determinant(gaussianSpaceMatrix));
	g_vrk +=  clamp( (dVrk / (2.0 * PI)) * exp(-0.5 * distanceEval), 0.0, 1.0);

	// Paramètre de l'espace de la gaussienne : Noyau 1 (gaussienne normale shifter de 0.5 en xyz)
    shift = move(mat4(1.0),vec3(0.0) + kernelPos);
    rotation = rotate(mat4(1.0),vec3(1.0,0.0,0.0),PI_4);	// Todo 
    scale = rescale(mat4(1.0),vec3(0.1,0.5,0.1) * kernelScale);
    gaussianSpaceMatrix = shift * rotation * scale;  
    gaussianSpaceMatrix = inverse(gaussianSpaceMatrix);
	_Vrk = transpose(gaussianSpaceMatrix) * gaussianBase * gaussianSpaceMatrix;
    distanceEval = (XtMY(vec4(evalPos,1.0),_Vrk,vec4(evalPos,1.0)));
	dVrk = sqrt(determinant(gaussianSpaceMatrix));
	g_vrk +=  clamp( (dVrk / (2.0 * PI)) * exp(-0.5 * distanceEval), 0.0, 1.0); 
    
    // Paramètre de l'espace de la gaussienne : Noyau 1 (gaussienne normale shifter de 0.5 en xyz)
    shift = move(mat4(1.0),vec3(0.0) + kernelPos);
    rotation = rotate(mat4(1.0),vec3(1.0,0.0,0.0),PI_4);	// Todo 
    scale = rescale(mat4(1.0),vec3(0.5,0.1,0.1) * kernelScale);
    gaussianSpaceMatrix = shift * rotation * scale;  
    gaussianSpaceMatrix = inverse(gaussianSpaceMatrix);
	_Vrk = transpose(gaussianSpaceMatrix) * gaussianBase * gaussianSpaceMatrix;
    distanceEval = (XtMY(vec4(evalPos,1.0),_Vrk,vec4(evalPos,1.0)));
	dVrk = sqrt(determinant(gaussianSpaceMatrix));
	g_vrk +=  clamp( (dVrk / (2.0 * PI)) * exp(-0.5 * distanceEval), 0.0, 1.0);
        
    return ( (g_vrk = clamp(power * g_vrk,0.0, 1.0)) < 0.01 ? 0.0 : g_vrk) ;
    
}

vec4 colorFromIntRGB(int R, int G, int B)
{
	return vec4(R,G,B,255.0f) / 255.0f;
}

#endif
